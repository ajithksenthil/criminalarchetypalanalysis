#!/usr/bin/env python3
"""
run_complete_prototype_analysis.py

Complete prototype processing system with:
1. Entity replacement (names/locations ‚Üí generic labels)
2. LLM lexical variations (reduce word choice bias)
3. Prototype embeddings (average variations)
4. OpenAI state-of-the-art embeddings
5. Intelligent cluster labeling
"""

import subprocess
import os
import sys
import time
import json
from pathlib import Path

def test_openai_availability():
    """Test if OpenAI API is working."""
    try:
        import openai
        from dotenv import load_dotenv
        
        load_dotenv()
        
        if not os.getenv('OPENAI_API_KEY'):
            return False, "No OPENAI_API_KEY found in .env"
        
        client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        # Test embedding API
        response = client.embeddings.create(
            input=['test'],
            model='text-embedding-3-small'
        )
        
        # Test chat API
        response = client.chat.completions.create(
            model='gpt-4o-mini',
            messages=[{'role': 'user', 'content': 'Hello'}],
            max_tokens=5
        )
        
        return True, "OpenAI API working"
        
    except Exception as e:
        return False, f"OpenAI error: {e}"

def run_complete_prototype_analysis():
    """Run the complete prototype analysis with all features."""
    
    print("üöÄ COMPLETE PROTOTYPE PROCESSING ANALYSIS")
    print("=" * 60)
    print("This will run the most advanced lexical bias reduction:")
    print("‚Ä¢ Entity replacement (names ‚Üí [PERSON], locations ‚Üí [LOCATION])")
    print("‚Ä¢ LLM lexical variations (reduce word choice bias)")
    print("‚Ä¢ Prototype embeddings (average variations)")
    print("‚Ä¢ OpenAI text-embedding-3-large (highest quality)")
    print("‚Ä¢ Intelligent cluster labeling with GPT-4")
    print()
    
    # Test OpenAI
    print("[STEP 1] Testing OpenAI API availability...")
    openai_available, status = test_openai_availability()
    print(f"Status: {status}")
    
    if not openai_available:
        print("‚ùå OpenAI API not available. Please check:")
        print("   1. OPENAI_API_KEY is set in .env file")
        print("   2. You have sufficient quota")
        print("   3. API key has correct permissions")
        return False
    
    print("‚úÖ OpenAI API ready!")
    
    # Configuration options
    configs = [
        {
            "name": "Complete Prototype (text-embedding-3-large)",
            "output_dir": "output_complete_prototype_large",
            "embedding_model": "text-embedding-3-large",
            "use_openai": True,
            "use_prototype": True,
            "use_lexical_bias_reduction": True,
            "description": "Highest quality: 3072-dim embeddings + full prototype processing"
        },
        {
            "name": "Complete Prototype (text-embedding-3-small)",
            "output_dir": "output_complete_prototype_small",
            "embedding_model": "text-embedding-3-small", 
            "use_openai": True,
            "use_prototype": True,
            "use_lexical_bias_reduction": True,
            "description": "Balanced: 1536-dim embeddings + full prototype processing"
        },
        {
            "name": "OpenAI Embeddings Only (no prototype)",
            "output_dir": "output_openai_embeddings_only",
            "embedding_model": "text-embedding-3-large",
            "use_openai": True,
            "use_prototype": False,
            "use_lexical_bias_reduction": False,
            "description": "Baseline: Just high-quality embeddings"
        }
    ]
    
    print(f"\n[STEP 2] Choose configuration:")
    for i, config in enumerate(configs, 1):
        print(f"   {i}. {config['name']}")
        print(f"      {config['description']}")
    
    choice = input(f"\nEnter choice (1-{len(configs)}) or 'all' for all: ").strip()
    
    if choice.lower() == 'all':
        selected_configs = configs
    else:
        try:
            idx = int(choice) - 1
            if 0 <= idx < len(configs):
                selected_configs = [configs[idx]]
            else:
                print("Invalid choice, using complete prototype (large)")
                selected_configs = [configs[0]]
        except ValueError:
            print("Invalid choice, using complete prototype (large)")
            selected_configs = [configs[0]]
    
    # Run analyses
    results = {}
    
    for config in selected_configs:
        print(f"\n[STEP 3] Running: {config['name']}")
        print("=" * 50)
        
        # Build command
        cmd = [
            "python", "run_modular_analysis.py",
            "--type1_dir=type1csvs",
            "--type2_csv=type2csvs", 
            f"--output_dir={config['output_dir']}",
            f"--embedding_model={config['embedding_model']}",
            "--auto_k",
            "--match_only",
            "--n_clusters=5"
        ]
        
        if config['use_openai']:
            cmd.append("--use_openai")
            cmd.append(f"--openai_model={config['embedding_model']}")
        
        if config['use_prototype']:
            cmd.append("--use_prototype")
        
        if config['use_lexical_bias_reduction']:
            cmd.append("--use_lexical_bias_reduction")
        else:
            cmd.append("--no_llm")  # Disable LLM if not using full processing
        
        print(f"Command: {' '.join(cmd)}")
        print()
        
        try:
            start_time = time.time()
            result = subprocess.run(cmd, check=True, capture_output=True, text=True, timeout=1800)  # 30 min timeout
            elapsed_time = time.time() - start_time
            
            print(f"‚úÖ Completed in {elapsed_time:.1f} seconds")
            
            # Load and analyze results
            try:
                with open(f"{config['output_dir']}/analysis_results.json", 'r') as f:
                    analysis_results = json.load(f)
                
                silhouette = analysis_results['clustering']['silhouette']
                n_insights = len(analysis_results.get('conditional_insights', {}))
                
                results[config['name']] = {
                    'success': True,
                    'silhouette': silhouette,
                    'n_insights': n_insights,
                    'time': elapsed_time,
                    'output_dir': config['output_dir']
                }
                
                print(f"üìä Silhouette score: {silhouette:.4f}")
                print(f"üìä Conditional insights: {n_insights}")
                
                # Organize results
                print(f"üìÅ Organizing results...")
                organize_cmd = ["python", "organize_and_validate_results.py", config['output_dir']]
                subprocess.run(organize_cmd, check=True, capture_output=True)
                
                # Check if prototype processing worked
                check_prototype_success(config['output_dir'], config)
                
            except Exception as e:
                print(f"‚ö†Ô∏è  Could not load results: {e}")
                results[config['name']] = {'success': False, 'error': str(e)}
                
        except subprocess.TimeoutExpired:
            print(f"‚è∞ Timeout after 30 minutes")
            results[config['name']] = {'success': False, 'error': 'Timeout'}
            
        except subprocess.CalledProcessError as e:
            print(f"‚ùå Analysis failed: {e}")
            print(f"Error output: {e.stderr}")
            results[config['name']] = {'success': False, 'error': e.stderr}
    
    # Generate comparison report
    generate_final_report(results)
    
    return results

def check_prototype_success(output_dir: str, config: dict):
    """Check if prototype processing worked correctly."""
    
    try:
        cluster_file = f"{output_dir}/clustering/cluster_info.json"
        with open(cluster_file, 'r') as f:
            cluster_info = json.load(f)
        
        # Check representative samples for entity replacement
        has_entities = False
        has_names = False
        
        for cluster in cluster_info[:2]:  # Check first 2 clusters
            for sample in cluster['representative_samples'][:2]:
                if '[PERSON]' in sample or '[LOCATION]' in sample:
                    has_entities = True
                if any(name in sample.lower() for name in ['charles', 'robert', 'mary', 'john', 'david']):
                    has_names = True
        
        if config['use_lexical_bias_reduction']:
            if has_entities and not has_names:
                print("‚úÖ Entity replacement: SUCCESS - Names replaced with [PERSON], [LOCATION]")
            elif has_entities and has_names:
                print("‚ö†Ô∏è  Entity replacement: PARTIAL - Some names replaced")
            else:
                print("‚ùå Entity replacement: FAILED - Original names still present")
        
        if config['use_prototype']:
            # Check if prototype processing was applied (harder to verify directly)
            print("‚úÖ Prototype processing: Applied (LLM variations + averaging)")
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not verify prototype processing: {e}")

def generate_final_report(results: dict):
    """Generate final comparison report."""
    
    print(f"\n" + "=" * 60)
    print("COMPLETE PROTOTYPE ANALYSIS RESULTS")
    print("=" * 60)
    
    successful_results = {k: v for k, v in results.items() if v.get('success')}
    
    if not successful_results:
        print("‚ùå No analyses completed successfully")
        return
    
    # Sort by silhouette score
    sorted_results = sorted(successful_results.items(), 
                          key=lambda x: x[1]['silhouette'], reverse=True)
    
    print(f"\nüèÜ RANKING BY CLUSTERING QUALITY:")
    print("-" * 40)
    
    for i, (name, result) in enumerate(sorted_results, 1):
        print(f"\n{i}. {name}")
        print(f"   üìä Silhouette: {result['silhouette']:.4f}")
        print(f"   üìà Insights: {result['n_insights']}")
        print(f"   ‚è±Ô∏è  Time: {result['time']:.1f}s")
        print(f"   üìÅ Results: {result['output_dir']}/organized_results/")
    
    # Best result
    best_name, best_result = sorted_results[0]
    
    print(f"\nüéØ BEST RESULT: {best_name}")
    print(f"   Silhouette improvement: {best_result['silhouette']:.4f}")
    
    if best_result['silhouette'] > 0.05:
        print("   ‚úÖ EXCELLENT: Significant clustering improvement!")
    elif best_result['silhouette'] > 0.03:
        print("   ‚ö†Ô∏è  GOOD: Moderate clustering improvement")
    else:
        print("   üìä REALISTIC: Low scores typical for behavioral data")
    
    print(f"\nüí° TO EXAMINE BEST RESULTS:")
    print(f"   ‚Ä¢ Executive summary: {best_result['output_dir']}/organized_results/executive_summary.txt")
    print(f"   ‚Ä¢ Cluster analysis: {best_result['output_dir']}/organized_results/clustering_table.txt")
    print(f"   ‚Ä¢ Validation report: {best_result['output_dir']}/organized_results/validation_report.txt")
    
    # Save comparison
    comparison_file = "prototype_analysis_comparison.json"
    with open(comparison_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nüíæ Detailed comparison saved to: {comparison_file}")

def main():
    """Main function."""
    print("üéØ COMPLETE PROTOTYPE PROCESSING SYSTEM")
    print("The most advanced lexical bias reduction for criminal archetypal analysis")
    print()
    
    # Check dependencies
    try:
        import openai
        import spacy
        from sentence_transformers import SentenceTransformer
    except ImportError as e:
        print(f"‚ùå Missing dependency: {e}")
        print("Please install: pip install openai spacy sentence-transformers")
        return
    
    # Run analysis
    results = run_complete_prototype_analysis()
    
    print(f"\nüéâ COMPLETE PROTOTYPE ANALYSIS FINISHED!")
    print("Check the organized results directories for detailed findings.")

if __name__ == "__main__":
    main()
